{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee05e03",
   "metadata": {},
   "source": [
    "# Prepare environment\n",
    "\n",
    "## Configure jupyter\n",
    "\n",
    "* Install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install cmake\n",
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63c564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91588d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# run all code cells of the specified notebook\n",
    "%run ../face/image_utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b024405",
   "metadata": {},
   "source": [
    "# Use DeepFace library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "backend_names = [\"opencv\", \"ssd\", \"dlib\", \"mtcnn\", \"retinaface\", \"mediapipe\"]\n",
    "model_names = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"ArcFace\"]\n",
    "# model_names = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"ArcFace\", \"DeepID\", \"Dlib\", \"SFace\"]\n",
    "\n",
    "target_size=(224, 224)\n",
    "\n",
    "face_path = '/data/faces/'\n",
    "person_path = face_path + 'elon_musk/'\n",
    "face1 = person_path + 'image1.jpeg'\n",
    "face2 = person_path + 'image2.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for index, backend_name in enumerate(backend_names):\n",
    "    try:\n",
    "        face = DeepFace.detectFace(face1, target_size=target_size, detector_backend=backend_name)\n",
    "        axs[index].imshow(face)\n",
    "        axs[index].set_title(backend_name)\n",
    "        axs[index].axis('off')\n",
    "    except:\n",
    "        pass\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    result = DeepFace.verify(\n",
    "        img1_path = face1,\n",
    "        img2_path = face2,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    print(model_name, '=>', result)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    fig.suptitle(f'Verified {result[\"verified\"]} - Distance {result[\"distance\"]:0.4}')\n",
    "    \n",
    "    axs[0].imshow(plt.imread(face1))\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(plt.imread(face2))\n",
    "    axs[1].axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf035fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = DeepFace.find(img_path=face1, db_path=face_path)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f686b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_emotion(img_path, emo_df, figsize=(15, 5)):\n",
    "    img = cv2.cvtColor(img_path, cv2.COLOR_BGR2RGB)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=figsize)\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[0].imshow(img)\n",
    "    emo_df.sort_values(\"prediction\").plot(kind=\"barh\", figsize=figsize, ax=axs[1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "imgs = glob(person_path + \"*\")\n",
    "\n",
    "for img_path in imgs:\n",
    "    print(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    demo = DeepFace.analyze(img_path=img_path, \n",
    "                     detector_backend=backend_names[4])\n",
    "    emo_df = pd.DataFrame(demo[0][\"emotion\"], index=[0]).T.rename(\n",
    "        columns={0: \"prediction\"}\n",
    "    )\n",
    "    plot_img_emotion(img, emo_df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d10cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
